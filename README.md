# Wikipedia Dump Processing

This is collection of bash/python scripts and spark jobs aimed to parse SQL and XML dumps from Wikipedia (https://dumps.wikimedia.org/)
to prepare dataset for training GraphSAGE (https://github.com/pyalex/GraphSAGE) model on the task of 
Representation Learning for Wikipedia Articles. 